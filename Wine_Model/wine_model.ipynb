{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = pd.read_csv(r'C:\\Users\\Rishabh\\Downloads\\wines.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic_acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity_of_ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total_phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid_phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color_intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD280-OD315_of_diluted_wines</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>3</td>\n",
       "      <td>13.71</td>\n",
       "      <td>5.65</td>\n",
       "      <td>2.45</td>\n",
       "      <td>20.5</td>\n",
       "      <td>95</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.06</td>\n",
       "      <td>7.70</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.74</td>\n",
       "      <td>740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>3</td>\n",
       "      <td>13.40</td>\n",
       "      <td>3.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>23.0</td>\n",
       "      <td>102</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.41</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.56</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>3</td>\n",
       "      <td>13.27</td>\n",
       "      <td>4.28</td>\n",
       "      <td>2.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.35</td>\n",
       "      <td>10.20</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.56</td>\n",
       "      <td>835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>3</td>\n",
       "      <td>13.17</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.37</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.46</td>\n",
       "      <td>9.30</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.62</td>\n",
       "      <td>840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>3</td>\n",
       "      <td>14.13</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.74</td>\n",
       "      <td>24.5</td>\n",
       "      <td>96</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.35</td>\n",
       "      <td>9.20</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.60</td>\n",
       "      <td>560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Class  Alcohol  Malic_acid   Ash  Alcalinity_of_ash  Magnesium  \\\n",
       "0        1    14.23        1.71  2.43               15.6        127   \n",
       "1        1    13.20        1.78  2.14               11.2        100   \n",
       "2        1    13.16        2.36  2.67               18.6        101   \n",
       "3        1    14.37        1.95  2.50               16.8        113   \n",
       "4        1    13.24        2.59  2.87               21.0        118   \n",
       "..     ...      ...         ...   ...                ...        ...   \n",
       "173      3    13.71        5.65  2.45               20.5         95   \n",
       "174      3    13.40        3.91  2.48               23.0        102   \n",
       "175      3    13.27        4.28  2.26               20.0        120   \n",
       "176      3    13.17        2.59  2.37               20.0        120   \n",
       "177      3    14.13        4.10  2.74               24.5         96   \n",
       "\n",
       "     Total_phenols  Flavanoids  Nonflavanoid_phenols  Proanthocyanins  \\\n",
       "0             2.80        3.06                  0.28             2.29   \n",
       "1             2.65        2.76                  0.26             1.28   \n",
       "2             2.80        3.24                  0.30             2.81   \n",
       "3             3.85        3.49                  0.24             2.18   \n",
       "4             2.80        2.69                  0.39             1.82   \n",
       "..             ...         ...                   ...              ...   \n",
       "173           1.68        0.61                  0.52             1.06   \n",
       "174           1.80        0.75                  0.43             1.41   \n",
       "175           1.59        0.69                  0.43             1.35   \n",
       "176           1.65        0.68                  0.53             1.46   \n",
       "177           2.05        0.76                  0.56             1.35   \n",
       "\n",
       "     Color_intensity   Hue  OD280-OD315_of_diluted_wines  Proline  \n",
       "0               5.64  1.04                          3.92     1065  \n",
       "1               4.38  1.05                          3.40     1050  \n",
       "2               5.68  1.03                          3.17     1185  \n",
       "3               7.80  0.86                          3.45     1480  \n",
       "4               4.32  1.04                          2.93      735  \n",
       "..               ...   ...                           ...      ...  \n",
       "173             7.70  0.64                          1.74      740  \n",
       "174             7.30  0.70                          1.56      750  \n",
       "175            10.20  0.59                          1.56      835  \n",
       "176             9.30  0.60                          1.62      840  \n",
       "177             9.20  0.61                          1.60      560  \n",
       "\n",
       "[178 rows x 14 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     1  2  3\n",
       "0    1  0  0\n",
       "1    1  0  0\n",
       "2    1  0  0\n",
       "3    1  0  0\n",
       "4    1  0  0\n",
       "..  .. .. ..\n",
       "173  0  0  1\n",
       "174  0  0  1\n",
       "175  0  0  1\n",
       "176  0  0  1\n",
       "177  0  0  1\n",
       "\n",
       "[178 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.get_dummies(dt['Class'])\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dt.iloc[:,1:]\n",
    "#or X = dt.drop('Class',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectFromModel(estimator=Lasso(alpha=0.0001, copy_X=True, fit_intercept=True,\n",
       "                                max_iter=1000, normalize=False, positive=False,\n",
       "                                precompute=False, random_state=None,\n",
       "                                selection='cyclic', tol=0.0001,\n",
       "                                warm_start=False),\n",
       "                max_features=None, norm_order=1, prefit=False, threshold=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "#creates a model for feature selection\n",
    "#alpha value used to tell the dataset is small,default is 1.0\n",
    "sel = SelectFromModel(Lasso(alpha = 0.0001))\n",
    "sel.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#displays output if columns are important or not\n",
    "sel.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x26deea1da48>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot(x='Malic_acid' , y='Class' , data=dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 13)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units=6 , input_shape=(13,), \n",
    "                activation='relu', \n",
    "                kernel_initializer='he_normal' ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 6)                 84        \n",
      "=================================================================\n",
      "Total params: 84\n",
      "Trainable params: 84\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units=9, \n",
    "                activation='relu', \n",
    "                kernel_initializer='he_normal' ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 6)                 84        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 9)                 63        \n",
      "=================================================================\n",
      "Total params: 147\n",
      "Trainable params: 147\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units=15, \n",
    "                activation='relu', \n",
    "                kernel_initializer='he_normal' ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 6)                 84        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 9)                 63        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 15)                150       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 20)                320       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 9)                 189       \n",
      "=================================================================\n",
      "Total params: 806\n",
      "Trainable params: 806\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.add(Dense(units=20, \n",
    "                activation='relu', \n",
    "                kernel_initializer='he_normal' ))\n",
    "model.add(Dense(units=9, \n",
    "                activation='relu', \n",
    "                kernel_initializer='he_normal' ))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 6)                 84        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 9)                 63        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 15)                150       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 20)                320       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 9)                 189       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 3)                 30        \n",
      "=================================================================\n",
      "Total params: 836\n",
      "Trainable params: 836\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.add(Dense(units=3, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',  \n",
    "              loss='categorical_crossentropy',\n",
    "             metrics=['accuracy']\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/100\n",
      " - 0s - loss: 448.7647 - accuracy: 0.2817 - val_loss: 391.1894 - val_accuracy: 0.2222\n",
      "Epoch 2/100\n",
      " - 0s - loss: 318.0108 - accuracy: 0.2817 - val_loss: 257.9267 - val_accuracy: 0.2222\n",
      "Epoch 3/100\n",
      " - 0s - loss: 203.4320 - accuracy: 0.2817 - val_loss: 130.1290 - val_accuracy: 0.2222\n",
      "Epoch 4/100\n",
      " - 0s - loss: 112.6243 - accuracy: 0.1761 - val_loss: 92.2639 - val_accuracy: 0.3889\n",
      "Epoch 5/100\n",
      " - 0s - loss: 102.7539 - accuracy: 0.3169 - val_loss: 89.3847 - val_accuracy: 0.3889\n",
      "Epoch 6/100\n",
      " - 0s - loss: 99.1612 - accuracy: 0.3169 - val_loss: 81.2761 - val_accuracy: 0.3889\n",
      "Epoch 7/100\n",
      " - 0s - loss: 88.5547 - accuracy: 0.3169 - val_loss: 70.6870 - val_accuracy: 0.3889\n",
      "Epoch 8/100\n",
      " - 0s - loss: 76.6522 - accuracy: 0.3169 - val_loss: 59.3783 - val_accuracy: 0.3889\n",
      "Epoch 9/100\n",
      " - 0s - loss: 63.3693 - accuracy: 0.3169 - val_loss: 47.8162 - val_accuracy: 0.3889\n",
      "Epoch 10/100\n",
      " - 0s - loss: 50.0258 - accuracy: 0.3169 - val_loss: 36.9490 - val_accuracy: 0.3889\n",
      "Epoch 11/100\n",
      " - 0s - loss: 37.3393 - accuracy: 0.3028 - val_loss: 31.9664 - val_accuracy: 0.0556\n",
      "Epoch 12/100\n",
      " - 0s - loss: 32.6188 - accuracy: 0.0775 - val_loss: 28.9012 - val_accuracy: 0.0833\n",
      "Epoch 13/100\n",
      " - 0s - loss: 25.4634 - accuracy: 0.1056 - val_loss: 19.5865 - val_accuracy: 0.3889\n",
      "Epoch 14/100\n",
      " - 0s - loss: 21.1863 - accuracy: 0.3169 - val_loss: 16.6551 - val_accuracy: 0.3889\n",
      "Epoch 15/100\n",
      " - 0s - loss: 16.4810 - accuracy: 0.3169 - val_loss: 11.5124 - val_accuracy: 0.2500\n",
      "Epoch 16/100\n",
      " - 0s - loss: 10.9949 - accuracy: 0.1479 - val_loss: 9.9463 - val_accuracy: 0.1389\n",
      "Epoch 17/100\n",
      " - 0s - loss: 7.6723 - accuracy: 0.2465 - val_loss: 5.3290 - val_accuracy: 0.5000\n",
      "Epoch 18/100\n",
      " - 0s - loss: 5.0338 - accuracy: 0.4507 - val_loss: 4.0714 - val_accuracy: 0.4167\n",
      "Epoch 19/100\n",
      " - 0s - loss: 4.2984 - accuracy: 0.4296 - val_loss: 5.0564 - val_accuracy: 0.3889\n",
      "Epoch 20/100\n",
      " - 0s - loss: 4.3525 - accuracy: 0.4014 - val_loss: 3.5997 - val_accuracy: 0.4444\n",
      "Epoch 21/100\n",
      " - 0s - loss: 3.1803 - accuracy: 0.4296 - val_loss: 2.9927 - val_accuracy: 0.4444\n",
      "Epoch 22/100\n",
      " - 0s - loss: 3.2280 - accuracy: 0.3592 - val_loss: 2.9369 - val_accuracy: 0.3333\n",
      "Epoch 23/100\n",
      " - 0s - loss: 2.8941 - accuracy: 0.3380 - val_loss: 2.4964 - val_accuracy: 0.2778\n",
      "Epoch 24/100\n",
      " - 0s - loss: 2.3913 - accuracy: 0.3662 - val_loss: 2.1027 - val_accuracy: 0.5000\n",
      "Epoch 25/100\n",
      " - 0s - loss: 2.1646 - accuracy: 0.5634 - val_loss: 1.9541 - val_accuracy: 0.3611\n",
      "Epoch 26/100\n",
      " - 0s - loss: 1.8266 - accuracy: 0.3803 - val_loss: 1.6093 - val_accuracy: 0.5556\n",
      "Epoch 27/100\n",
      " - 0s - loss: 1.7659 - accuracy: 0.5211 - val_loss: 1.5681 - val_accuracy: 0.3056\n",
      "Epoch 28/100\n",
      " - 0s - loss: 1.1841 - accuracy: 0.5563 - val_loss: 0.9023 - val_accuracy: 0.6944\n",
      "Epoch 29/100\n",
      " - 0s - loss: 0.9757 - accuracy: 0.5845 - val_loss: 0.7685 - val_accuracy: 0.6667\n",
      "Epoch 30/100\n",
      " - 0s - loss: 0.9397 - accuracy: 0.6338 - val_loss: 0.9951 - val_accuracy: 0.3611\n",
      "Epoch 31/100\n",
      " - 0s - loss: 0.9965 - accuracy: 0.5986 - val_loss: 0.8035 - val_accuracy: 0.5556\n",
      "Epoch 32/100\n",
      " - 0s - loss: 0.8673 - accuracy: 0.6056 - val_loss: 0.5710 - val_accuracy: 0.8056\n",
      "Epoch 33/100\n",
      " - 0s - loss: 0.6865 - accuracy: 0.7606 - val_loss: 0.5239 - val_accuracy: 0.8056\n",
      "Epoch 34/100\n",
      " - 0s - loss: 0.7168 - accuracy: 0.7394 - val_loss: 0.4934 - val_accuracy: 0.9722\n",
      "Epoch 35/100\n",
      " - 0s - loss: 0.6609 - accuracy: 0.8239 - val_loss: 0.5093 - val_accuracy: 0.9444\n",
      "Epoch 36/100\n",
      " - 0s - loss: 0.6599 - accuracy: 0.8662 - val_loss: 0.5166 - val_accuracy: 0.8889\n",
      "Epoch 37/100\n",
      " - 0s - loss: 0.6347 - accuracy: 0.8099 - val_loss: 0.5053 - val_accuracy: 0.8056\n",
      "Epoch 38/100\n",
      " - 0s - loss: 0.7457 - accuracy: 0.6761 - val_loss: 0.7081 - val_accuracy: 0.5833\n",
      "Epoch 39/100\n",
      " - 0s - loss: 0.7279 - accuracy: 0.7324 - val_loss: 0.6379 - val_accuracy: 0.7500\n",
      "Epoch 40/100\n",
      " - 0s - loss: 0.7502 - accuracy: 0.6831 - val_loss: 0.4929 - val_accuracy: 0.9167\n",
      "Epoch 41/100\n",
      " - 0s - loss: 0.7421 - accuracy: 0.6972 - val_loss: 0.7202 - val_accuracy: 0.6111\n",
      "Epoch 42/100\n",
      " - 0s - loss: 0.9415 - accuracy: 0.5493 - val_loss: 0.7231 - val_accuracy: 0.7778\n",
      "Epoch 43/100\n",
      " - 0s - loss: 0.7043 - accuracy: 0.7042 - val_loss: 0.4815 - val_accuracy: 0.8333\n",
      "Epoch 44/100\n",
      " - 0s - loss: 0.6875 - accuracy: 0.7113 - val_loss: 0.5606 - val_accuracy: 0.7500\n",
      "Epoch 45/100\n",
      " - 0s - loss: 0.7377 - accuracy: 0.6690 - val_loss: 0.6033 - val_accuracy: 0.8333\n",
      "Epoch 46/100\n",
      " - 0s - loss: 0.6853 - accuracy: 0.6901 - val_loss: 0.5020 - val_accuracy: 0.9444\n",
      "Epoch 47/100\n",
      " - 0s - loss: 0.6535 - accuracy: 0.7606 - val_loss: 0.5051 - val_accuracy: 0.8056\n",
      "Epoch 48/100\n",
      " - 0s - loss: 0.5670 - accuracy: 0.8380 - val_loss: 0.4680 - val_accuracy: 0.9167\n",
      "Epoch 49/100\n",
      " - 0s - loss: 0.5541 - accuracy: 0.8239 - val_loss: 0.4733 - val_accuracy: 0.8611\n",
      "Epoch 50/100\n",
      " - 0s - loss: 0.5455 - accuracy: 0.8310 - val_loss: 0.5018 - val_accuracy: 0.8056\n",
      "Epoch 51/100\n",
      " - 0s - loss: 0.5725 - accuracy: 0.7958 - val_loss: 0.4720 - val_accuracy: 0.9167\n",
      "Epoch 52/100\n",
      " - 0s - loss: 0.5716 - accuracy: 0.8169 - val_loss: 0.4811 - val_accuracy: 0.8889\n",
      "Epoch 53/100\n",
      " - 0s - loss: 0.5603 - accuracy: 0.8310 - val_loss: 0.4662 - val_accuracy: 0.8333\n",
      "Epoch 54/100\n",
      " - 0s - loss: 0.5640 - accuracy: 0.8169 - val_loss: 0.4830 - val_accuracy: 0.8333\n",
      "Epoch 55/100\n",
      " - 0s - loss: 0.5603 - accuracy: 0.8239 - val_loss: 0.4460 - val_accuracy: 0.9722\n",
      "Epoch 56/100\n",
      " - 0s - loss: 0.5335 - accuracy: 0.8592 - val_loss: 0.4909 - val_accuracy: 0.8611\n",
      "Epoch 57/100\n",
      " - 0s - loss: 0.5662 - accuracy: 0.7746 - val_loss: 0.4630 - val_accuracy: 0.8611\n",
      "Epoch 58/100\n",
      " - 0s - loss: 0.5485 - accuracy: 0.8380 - val_loss: 0.4949 - val_accuracy: 0.7778\n",
      "Epoch 59/100\n",
      " - 0s - loss: 0.5434 - accuracy: 0.8169 - val_loss: 0.4483 - val_accuracy: 0.9444\n",
      "Epoch 60/100\n",
      " - 0s - loss: 0.5341 - accuracy: 0.7958 - val_loss: 0.4552 - val_accuracy: 0.9167\n",
      "Epoch 61/100\n",
      " - 0s - loss: 0.6349 - accuracy: 0.7606 - val_loss: 0.4306 - val_accuracy: 0.9722\n",
      "Epoch 62/100\n",
      " - 0s - loss: 0.5754 - accuracy: 0.7817 - val_loss: 0.6088 - val_accuracy: 0.7222\n",
      "Epoch 63/100\n",
      " - 0s - loss: 0.6615 - accuracy: 0.7042 - val_loss: 0.4662 - val_accuracy: 0.7778\n",
      "Epoch 64/100\n",
      " - 0s - loss: 0.5872 - accuracy: 0.7324 - val_loss: 0.4685 - val_accuracy: 0.8611\n",
      "Epoch 65/100\n",
      " - 0s - loss: 0.5232 - accuracy: 0.8310 - val_loss: 0.4344 - val_accuracy: 0.9444\n",
      "Epoch 66/100\n",
      " - 0s - loss: 0.5701 - accuracy: 0.7606 - val_loss: 0.5312 - val_accuracy: 0.7500\n",
      "Epoch 67/100\n",
      " - 0s - loss: 0.5886 - accuracy: 0.7113 - val_loss: 0.4238 - val_accuracy: 0.9167\n",
      "Epoch 68/100\n",
      " - 0s - loss: 0.5132 - accuracy: 0.7958 - val_loss: 0.4181 - val_accuracy: 0.9167\n",
      "Epoch 69/100\n",
      " - 0s - loss: 0.5653 - accuracy: 0.8028 - val_loss: 0.5027 - val_accuracy: 0.7778\n",
      "Epoch 70/100\n",
      " - 0s - loss: 0.5517 - accuracy: 0.8239 - val_loss: 0.4237 - val_accuracy: 0.8889\n",
      "Epoch 71/100\n",
      " - 0s - loss: 0.6057 - accuracy: 0.7254 - val_loss: 0.5249 - val_accuracy: 0.7500\n",
      "Epoch 72/100\n",
      " - 0s - loss: 0.6323 - accuracy: 0.7254 - val_loss: 0.4025 - val_accuracy: 0.9722\n",
      "Epoch 73/100\n",
      " - 0s - loss: 0.5653 - accuracy: 0.7676 - val_loss: 0.4402 - val_accuracy: 0.9167\n",
      "Epoch 74/100\n",
      " - 0s - loss: 0.5599 - accuracy: 0.7535 - val_loss: 0.5918 - val_accuracy: 0.7778\n",
      "Epoch 75/100\n",
      " - 0s - loss: 0.7124 - accuracy: 0.6408 - val_loss: 0.4342 - val_accuracy: 0.8333\n",
      "Epoch 76/100\n",
      " - 0s - loss: 0.5864 - accuracy: 0.7324 - val_loss: 0.4509 - val_accuracy: 0.8056\n",
      "Epoch 77/100\n",
      " - 0s - loss: 0.6245 - accuracy: 0.6972 - val_loss: 0.4456 - val_accuracy: 0.8611\n",
      "Epoch 78/100\n",
      " - 0s - loss: 0.5811 - accuracy: 0.7394 - val_loss: 0.5743 - val_accuracy: 0.8333\n",
      "Epoch 79/100\n",
      " - 0s - loss: 0.5775 - accuracy: 0.7394 - val_loss: 0.3901 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      " - 0s - loss: 0.5110 - accuracy: 0.8380 - val_loss: 0.4347 - val_accuracy: 0.8056\n",
      "Epoch 81/100\n",
      " - 0s - loss: 0.4926 - accuracy: 0.8521 - val_loss: 0.3830 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      " - 0s - loss: 0.5003 - accuracy: 0.7958 - val_loss: 0.4132 - val_accuracy: 0.9167\n",
      "Epoch 83/100\n",
      " - 0s - loss: 0.4891 - accuracy: 0.8239 - val_loss: 0.3822 - val_accuracy: 0.9167\n",
      "Epoch 84/100\n",
      " - 0s - loss: 0.4832 - accuracy: 0.8662 - val_loss: 0.5141 - val_accuracy: 0.8056\n",
      "Epoch 85/100\n",
      " - 0s - loss: 0.5091 - accuracy: 0.8169 - val_loss: 0.4599 - val_accuracy: 0.7500\n",
      "Epoch 86/100\n",
      " - 0s - loss: 0.5182 - accuracy: 0.7676 - val_loss: 0.3798 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/100\n",
      " - 0s - loss: 0.5143 - accuracy: 0.8310 - val_loss: 0.3725 - val_accuracy: 0.9444\n",
      "Epoch 88/100\n",
      " - 0s - loss: 0.4943 - accuracy: 0.8380 - val_loss: 0.6175 - val_accuracy: 0.7500\n",
      "Epoch 89/100\n",
      " - 0s - loss: 0.6000 - accuracy: 0.7183 - val_loss: 0.4723 - val_accuracy: 0.7778\n",
      "Epoch 90/100\n",
      " - 0s - loss: 0.5651 - accuracy: 0.7465 - val_loss: 0.5140 - val_accuracy: 0.7222\n",
      "Epoch 91/100\n",
      " - 0s - loss: 0.6580 - accuracy: 0.6901 - val_loss: 0.3802 - val_accuracy: 0.9444\n",
      "Epoch 92/100\n",
      " - 0s - loss: 0.5119 - accuracy: 0.7887 - val_loss: 0.4181 - val_accuracy: 0.8889\n",
      "Epoch 93/100\n",
      " - 0s - loss: 0.4778 - accuracy: 0.8169 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 94/100\n",
      " - 0s - loss: 0.5275 - accuracy: 0.7676 - val_loss: 0.3645 - val_accuracy: 0.9444\n",
      "Epoch 95/100\n",
      " - 0s - loss: 0.5653 - accuracy: 0.7465 - val_loss: 0.5143 - val_accuracy: 0.8056\n",
      "Epoch 96/100\n",
      " - 0s - loss: 0.5690 - accuracy: 0.7465 - val_loss: 0.5692 - val_accuracy: 0.7778\n",
      "Epoch 97/100\n",
      " - 0s - loss: 0.7084 - accuracy: 0.7254 - val_loss: 0.6848 - val_accuracy: 0.6111\n",
      "Epoch 98/100\n",
      " - 0s - loss: 0.5919 - accuracy: 0.7254 - val_loss: 0.4795 - val_accuracy: 0.8611\n",
      "Epoch 99/100\n",
      " - 0s - loss: 0.5437 - accuracy: 0.7394 - val_loss: 0.3788 - val_accuracy: 0.9167\n",
      "Epoch 100/100\n",
      " - 0s - loss: 0.4652 - accuracy: 0.8873 - val_loss: 0.3474 - val_accuracy: 0.9722\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x26df5302a48>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, verbose = 2, validation_data = (X_test, y_test),epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('wine_model.hd5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.7646550e-01, 4.7935879e-01, 1.4417580e-01],\n",
       "       [7.5634235e-01, 1.7141519e-01, 7.2242543e-02],\n",
       "       [9.0996012e-02, 2.9263821e-01, 6.1636579e-01],\n",
       "       [9.6291828e-01, 3.6582969e-02, 4.9875304e-04],\n",
       "       [1.9786602e-01, 5.3444415e-01, 2.6768973e-01],\n",
       "       [9.0563041e-01, 9.0757012e-02, 3.6125011e-03],\n",
       "       [1.6566373e-01, 5.6023228e-01, 2.7410403e-01],\n",
       "       [1.2423085e-01, 1.8432269e-01, 6.9144648e-01],\n",
       "       [2.8569812e-01, 6.2013030e-01, 9.4171561e-02],\n",
       "       [3.7935066e-01, 2.3258698e-01, 3.8806239e-01],\n",
       "       [5.5064976e-01, 3.7734854e-01, 7.2001748e-02],\n",
       "       [2.3000300e-02, 2.6497746e-01, 7.1202224e-01],\n",
       "       [8.6336946e-01, 1.2876189e-01, 7.8686811e-03],\n",
       "       [9.4648026e-02, 5.4129797e-01, 3.6405405e-01],\n",
       "       [9.6495384e-01, 3.3876281e-02, 1.1698439e-03],\n",
       "       [5.9733566e-02, 9.0147829e-01, 3.8788203e-02],\n",
       "       [9.7165853e-02, 7.0728606e-01, 1.9554801e-01],\n",
       "       [3.0795330e-01, 5.0091881e-01, 1.9112794e-01],\n",
       "       [8.6153388e-01, 1.3196334e-01, 6.5028449e-03],\n",
       "       [9.0147652e-02, 7.2500122e-01, 1.8485107e-01],\n",
       "       [9.9967802e-01, 6.6182511e-05, 2.5587284e-04],\n",
       "       [2.4387713e-01, 6.8116868e-01, 7.4954249e-02],\n",
       "       [2.4340652e-01, 5.0448519e-01, 2.5210828e-01],\n",
       "       [1.9086314e-02, 9.9101298e-02, 8.8181239e-01],\n",
       "       [3.6680102e-02, 1.3327956e-01, 8.3004028e-01],\n",
       "       [8.2451813e-02, 1.5111157e-01, 7.6643658e-01],\n",
       "       [5.8616698e-03, 9.9411941e-01, 1.8978562e-05],\n",
       "       [2.7087456e-01, 5.8382440e-01, 1.4530098e-01],\n",
       "       [1.3846287e-01, 5.8882397e-01, 2.7271318e-01],\n",
       "       [7.7970630e-01, 1.7956433e-01, 4.0729471e-02],\n",
       "       [8.4895366e-01, 1.4572278e-01, 5.3236065e-03],\n",
       "       [7.1651109e-02, 8.1224531e-01, 1.1610353e-01],\n",
       "       [2.9152045e-01, 2.6319003e-01, 4.4528952e-01],\n",
       "       [9.9853873e-01, 9.5783628e-04, 5.0334446e-04],\n",
       "       [9.9729639e-01, 1.9997293e-03, 7.0390169e-04],\n",
       "       [8.7663114e-01, 1.2132106e-01, 2.0477879e-03]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
